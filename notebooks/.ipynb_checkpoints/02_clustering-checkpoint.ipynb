{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import sys\n",
    "import pandas\n",
    "import math\n",
    "from pandas.io import sql\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import os\n",
    "from configobj import ConfigObj\n",
    "import contextlib\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from functions.utils import database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define paths and variables\n",
    "\n",
    "config_path = \"/home/jovyan/shared/rural_planner_refactoring/config_files_test/config_co\"\n",
    "\n",
    "parser = ConfigObj(config_path)\n",
    "\n",
    "sql_path =  parser['sql_path']\n",
    "country_folder = parser['country_folder']\n",
    "schema = parser['clustering_params']['schema']\n",
    "\n",
    "\n",
    "output_table = parser['clustering_params']['output_table']\n",
    "table_transport = parser['clustering_params']['table_transport']\n",
    "table_infrastructure = parser['clustering_params']['table_infrastructure']\n",
    "table_settlements = parser['clustering_params']['table_settlements']\n",
    "table_coverage = parser['clustering_params']['table_coverage']\n",
    "table_franchises = parser['clustering_params']['table_franchises']\n",
    "table_nodes_original = parser['clustering_params']['table_nodes_original']\n",
    "table_nodes = parser['clustering_params']['table_nodes']\n",
    "table_schools   = parser['clustering_params']['table_schools']\n",
    "\n",
    "radius = int(parser['clustering_params']['max_coverage_radius'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create node table\n",
    "\n",
    "query_path = sql_path + '/' + country_folder + '/' + 'clustering_create_node_table.sql'\n",
    "\n",
    "with open(query_path) as file, database(parser) as db:\n",
    "    query = file.read()\n",
    "    query_formatted = query.format(schema = schema,\n",
    "                               table_coverage = table_coverage,\n",
    "                               table_settlements = table_settlements,\n",
    "                               table_infrastructure = table_infrastructure,\n",
    "                               table_nodes_original = table_nodes_original,\n",
    "                               table_franchises = table_franchises,\n",
    "                               table_transport = table_transport)\n",
    "    db.execute(query_formatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create node table copy\n",
    "\n",
    "query_path = sql_path + '/' + 'clustering_create_node_table_copy.sql'\n",
    "\n",
    "with open(query_path) as file, database(parser) as db:\n",
    "    query = file.read()\n",
    "    query_formatted = query.format(schema = schema,\n",
    "                                   table_nodes = table_nodes,\n",
    "                               table_nodes_original = table_nodes_original)\n",
    "    db.execute(query_formatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clusters with tx\n",
    "\n",
    "query_path = sql_path + '/' + country_folder + '/' + 'clustering_towers_priority_1.sql'\n",
    "\n",
    "with open(query_path) as file, database(parser) as db:\n",
    "    query = file.read()\n",
    "    query_formatted = query.format(schema = schema,\n",
    "                             table_nodes = table_nodes,\n",
    "                             radius = radius,\n",
    "                             table_infrastructure = table_infrastructure,\n",
    "                             table_coverage = table_coverage)\n",
    "    clusters_towers_p1 = pd.read_sql_query(query_formatted, db)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete already assigned nodes from node_table\n",
    "\n",
    "query_path = sql_path + '/' + 'clustering_delete_assigned_nodes.sql'\n",
    "\n",
    "excluded_ids = ''    \n",
    "\n",
    "for i in range(0, len(clusters_towers_p1)-1):\n",
    "    if (clusters_towers_p1.iloc[i]['nodes'] == ''):\n",
    "        nodes = '\\', '\n",
    "    else:\n",
    "        nodes = '\\', ' + clusters_towers_p1.iloc[i]['nodes'] + ', '\n",
    "    excluded_ids =   excluded_ids +  ' \\'' + clusters_towers_p1.iloc[i]['centroid'] + nodes\n",
    "\n",
    "if (clusters_towers_p1.iloc[i]['nodes'] == ''):\n",
    "    nodes_end = ''\n",
    "else:\n",
    "    nodes_end = clusters_towers_p1.iloc[len(clusters_towers_p1)-1]['nodes'] + ', '\n",
    "excluded_ids =   excluded_ids + nodes_end + ' \\'' + clusters_towers_p1.iloc[len(clusters_towers_p1)-1]['centroid']+ '\\''\n",
    "\n",
    "with open(query_path) as file, database(parser) as db:\n",
    "    query = file.read()\n",
    "    query_formatted = query.format(schema = schema,\n",
    "                             table_nodes = table_nodes,\n",
    "                             excluded_ids = excluded_ids)\n",
    "    db.execute(query_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering for towers with no tx\n",
    "\n",
    "query_path = sql_path + '/' + country_folder + '/' + 'clustering_towers_priority_2.sql'\n",
    "\n",
    "with open(query_path) as file, database(parser) as db:\n",
    "    query = file.read()\n",
    "    query_formatted = query.format(schema = schema,\n",
    "                             table_nodes = table_nodes,\n",
    "                             radius = radius,\n",
    "                             table_infrastructure = table_infrastructure,\n",
    "                             table_coverage = table_coverage)\n",
    "    clusters_towers_p2 = pd.read_sql_query(query_formatted, db)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete already assigned nodes from node_table\n",
    "\n",
    "query_path = sql_path + '/' + 'clustering_delete_assigned_nodes.sql'\n",
    "\n",
    "excluded_ids = ''\n",
    "\n",
    "for i in range(0, len(clusters_towers_p2)-1):\n",
    "    if (clusters_towers_p2.iloc[i]['nodes'] == ''):\n",
    "        nodes = '\\', '\n",
    "    else:\n",
    "        nodes = '\\', ' + clusters_towers_p2.iloc[i]['nodes'] + ', '\n",
    "    excluded_ids =   excluded_ids +  ' \\'' + clusters_towers_p2.iloc[i]['centroid'] + nodes\n",
    "\n",
    "if (clusters_towers_p2.iloc[i]['nodes'] == ''):\n",
    "    nodes_end = ''\n",
    "else:\n",
    "    nodes_end = clusters_towers_p2.iloc[len(clusters_towers_p2)-1]['nodes'] + ', '\n",
    "excluded_ids =   excluded_ids + nodes_end + ' \\'' + clusters_towers_p2.iloc[len(clusters_towers_p2)-1]['centroid']+ '\\''\n",
    "\n",
    "with open(query_path) as file, database(parser) as db:\n",
    "    query = file.read()\n",
    "    query_formatted = query.format(schema = schema,\n",
    "                             table_nodes = table_nodes,\n",
    "                             excluded_ids = excluded_ids)\n",
    "    db.execute(query_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete nodes that are towers\n",
    "\n",
    "query_path = sql_path + '/' + country_folder + '/' + 'clustering_delete_unwanted_nodes.sql'\n",
    "\n",
    "with open(query_path) as file, database(parser) as db:\n",
    "    query = file.read()\n",
    "    query_formatted = query.format(schema = schema,\n",
    "                                   table_nodes = table_nodes)\n",
    "    db.execute(query_formatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering for SETTLEMENTS\n",
    "\n",
    "query_path = sql_path + '/' + country_folder + '/' + 'clustering_settlements.sql'\n",
    "del_query_path = sql_path + '/' + 'clustering_delete_assigned_nodes.sql'\n",
    "\n",
    "with open(query_path) as file, open(del_query_path) as del_file, database(parser) as db:\n",
    "    query = file.read()\n",
    "    query_formatted = query.format(schema = schema,\n",
    "                             table_nodes = table_nodes,\n",
    "                             table_coverage = table_coverage,\n",
    "                             table_franchises = table_franchises,\n",
    "                             table_schools = table_schools,\n",
    "                             radius = radius)\n",
    "    \n",
    "    del_query = del_file.read()\n",
    "    del_query_formatted = del_query.format(schema = schema, \n",
    "                             table_nodes = table_nodes,\n",
    "                            excluded_ids = excluded_ids)\n",
    "    \n",
    "    df_clusters_int = pd.read_sql_query(query_formatted, db)\n",
    "    clusters_greenfield = pd.DataFrame(columns = df_clusters_int.columns)\n",
    "\n",
    "    num_nodes = 0\n",
    "    excluded_ids = ''\n",
    "    \n",
    "    #We cluster the rest of nodes iteratively\n",
    "    i = 0\n",
    "    while(not df_clusters_int.empty):\n",
    "        i = i + 1\n",
    "\n",
    "        excluded_ids = df_clusters_int.iloc[0]['nodes'] + ', \\'' + df_clusters_int.iloc[0]['centroid'] + '\\''\n",
    "\n",
    "        del_query_formatted=del_query.format(schema = schema, \n",
    "                                 table_nodes = table_nodes,\n",
    "                                excluded_ids = excluded_ids)\n",
    "\n",
    "        db.execute(del_query_formatted) \n",
    "\n",
    "        num_nodes = num_nodes + df_clusters_int.iloc[0]['cluster_size']\n",
    "\n",
    "        clusters_greenfield = clusters_greenfield.append(df_clusters_int, ignore_index=True)\n",
    "\n",
    "        df_clusters_int = pd.read_sql_query(query_formatted,con=db)\n",
    "\n",
    "        if(i%10 == 0):\n",
    "            print(str(datetime.now()))\n",
    "            print(\"Iteration \" + str(i) + \" with \" + str(num_nodes) + \" nodes clustered.\")\n",
    "            print(df_clusters_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data frame with the unclustered nodes to include them as one-node clusters\n",
    "\n",
    "query_path = sql_path + '/' + 'clustering_clusters_unclustered.sql'\n",
    "\n",
    "with open(query_path) as file, database(parser) as db:\n",
    "    query = file.read()\n",
    "    query_formatted = query.format(schema = schema,\n",
    "                                   table_nodes = table_nodes)\n",
    "    clusters_unclustered = pd.read_sql_query(query_formatted, db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters  = clusters_towers_p1.append(clusters_towers_p2, ignore_index=True).append(clusters_greenfield, ignore_index=True).append(clusters_unclustered, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sqlalchemy/dialects/postgresql/base.py:2690: SAWarning: Did not recognize type 'geography' of column 'geom_centroid'\n",
      "  (attype, name))\n"
     ]
    }
   ],
   "source": [
    "#Create final data frame with all clusters        \n",
    "\n",
    "query_path = sql_path + '/' + 'clustering_add_geom_clusters.sql'\n",
    "\n",
    "with open(query_path) as file, database(parser) as db:    \n",
    "    clusters.to_sql(output_table, con=db, if_exists = 'replace', schema = schema, index = False, \n",
    "                dtype = {'centroid_weight': sqlalchemy.types.Integer(),\n",
    "                         'cluster_weight': sqlalchemy.types.Integer(),\n",
    "                         'cluster_size': sqlalchemy.types.Integer()\n",
    "                        })\n",
    "    query = file.read()\n",
    "    query_formatted = query.format(schema = schema,\n",
    "                                   output_table = output_table,\n",
    "                               table_nodes_original = table_nodes_original)\n",
    "    db.execute(query_formatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create links data frame\n",
    "\n",
    "query_path = sql_path + '/' + 'clustering_create_clusters_links.sql'\n",
    "\n",
    "with open(query_path) as file, database(parser) as db:\n",
    "    query = file.read()\n",
    "    query_formatted = query.format(schema = schema,\n",
    "                                   output_table = output_table,\n",
    "                               table_nodes_original = table_nodes_original)\n",
    "    db.execute(query_formatted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
